"""
Codes for bachelor degree project:
    "CIFAR-10 Classification Task Based on ResNet-18 and D-RISE Salience Map Analysis"

2024 Spring semester 

Author: Xin Tang

Including:
    
    1, ResNet-18 modelling
    2， Data augmentation
    3， plotting learning curve, confusion matrix
    4, Salinecy map generated by D-RISE algorithm
    
"""



import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras import datasets
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.ndimage import zoom
import random


"""
Define classes for ResNet-18 modelling
"""

class BasicBlock(tf.keras.Model):
    """
    Basic residual block in resnet18
    """
    expansion = 1
    
    def __init__(self, in_channels, out_channels, strides=1):
        super(BasicBlock, self).__init__()
        self.conv1 = layers.Conv2D(out_channels, kernel_size=3, strides=strides, padding='same', use_bias=False)
        self.bn1 = layers.BatchNormalization()
        self.conv2 = layers.Conv2D(out_channels, kernel_size=3, strides=1, padding='same', use_bias=False)
        self.bn2 = layers.BatchNormalization()
        
        if strides != 1 or in_channels != self.expansion*out_channels:
            self.shortcut = tf.keras.Sequential([
                layers.Conv2D(self.expansion*out_channels, kernel_size=1, strides=strides, use_bias=False), 
                layers.BatchNormalization()
            ])
        else:
            self.shortcut = lambda x: x
            
    def call(self, x):
        out = tf.keras.activations.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out = layers.add([self.shortcut(x), out])
        out = tf.keras.activations.relu(out)
        return out


class BuildResNet(tf.keras.Model):
    """
    Build the architecture of the resnet18
    """
    def __init__(self, block, num_blocks, num_classes):
        super(BuildResNet, self).__init__()
        self.in_channels = 64
        
        self.conv1 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)
        self.bn1 = layers.BatchNormalization()
        self.layer1 = self._make_layer(block, 64, num_blocks[0], strides=1)
        self.layer2 = self._make_layer(block, 128, num_blocks[1], strides=2)
        self.layer3 = self._make_layer(block, 256, num_blocks[2], strides=2)
        self.layer4 = self._make_layer(block, 512, num_blocks[3], strides=2)
        self.avg_pool2d = layers.AveragePooling2D(pool_size=4)
        self.flatten = layers.Flatten()
        self.fc = layers.Dense(num_classes, activation='softmax')
    
    def call(self, x):
        out = tf.keras.activations.relu(self.bn1(self.conv1(x)))
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = self.avg_pool2d(out)
        out = self.flatten(out)
        out = self.fc(out)
        return out
    
    def _make_layer(self, block, out_channels, num_blocks, strides):
        stride = [strides] + [1]*(num_blocks-1)
        layer = []
        for s in stride:
            layer += [block(self.in_channels, out_channels, s)]
            self.in_channels = out_channels * block.expansion
        return tf.keras.Sequential(layer)
    

def ResNet18():
    """
    call the classes to generate a ResNet-18 model (an object)
    """

    return BuildResNet(BasicBlock, [2, 2, 2, 2], 10)

        
"""
Data preparation (including data augmentation)
"""

def get_dataset(validation_split=0.2):
    """
    Download, parse, process a dataset, and split train data into training and validation sets.
    """
    
    (train_images, train_labels), (test_images_original, test_labels) = datasets.cifar10.load_data()
    
    # Normalize pixel values to be between 0 and 1
    train_images, test_images = train_images / 255.0, test_images_original / 255.0
    
    # One-hot labels
    train_labels = _one_hot(train_labels, 10)
    test_labels = _one_hot(test_labels, 10)
    
    # Split train data into training and validation sets
    num_train = int((1 - validation_split) * len(train_images))
    train_images, valid_images = train_images[:num_train], train_images[num_train:]
    train_labels, valid_labels = train_labels[:num_train], train_labels[num_train:]
    
    return train_images, train_labels, valid_images, valid_labels, test_images, test_labels, test_images_original


def get_mean_and_std(images):
    """
    Compute the mean and std value of dataset.
    """
    mean = np.mean(images, axis=(0, 1, 2))
    std = np.std(images, axis=(0, 1, 2))
    return mean, std

def normalize(images, mean, std):
    """
    Normalize data with mean and std.
    """
    return (images - mean) / std

def dataset_generator(images, labels, batch_size):
    """
    generate dataset by using data augmentation 
    """
    ds = tf.data.Dataset.from_tensor_slices((images, labels))
    ds = ds.map(_augment_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    ds = ds.shuffle(len(images)).batch(batch_size)
    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
    return ds

def _one_hot(train_labels, num_classes, dtype=np.float32):
    """
    Create a one-hot encoding of labels of size num_classes.
    """
    return np.array(train_labels == np.arange(num_classes), dtype)

def _augment_fn(images, labels):
    """
    data augmentation skills
    """
    images = tf.image.pad_to_bounding_box(images, padding, padding, target_size, target_size)
    images = tf.image.random_crop(images, (image_size, image_size, 3))
    images = tf.image.random_flip_left_right(images)
    return images, labels


        
"""
Model training
"""

     
def main(batch_size, learning_rate, optimizer_type, epoch):
    """
    
    """

    print('==> Preparing data...')
    
    # get train, valid, test images and labels
    train_images, train_labels, valid_images, valid_labels, test_images, test_labels, test_images_original = get_dataset()
    
    # normalization
    mean, std = get_mean_and_std(train_images)
    train_images = normalize(train_images, mean, std)
    valid_images = normalize(valid_images, mean, std)  
    test_images = normalize(test_images, mean, std)
    
    # apply data augmentation    
    train_ds = dataset_generator(train_images, train_labels, batch_size) 
    valid_ds = dataset_generator(valid_images, valid_labels, batch_size)  # 创建验证数据集
    test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
    
    # learning decay
    decay_steps = int(epoch * len(train_images) / batch_size)
    learning_rate_fn = tf.keras.experimental.CosineDecay(initial_learning_rate=learning_rate, decay_steps=decay_steps, alpha=0.0)
   
    print('==> Building model...')
    model = ResNet18()

    # to make code flexible but here we just choose SGD
    if optimizer_type == 'SGD':
        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate_fn, momentum=0.9)
    elif optimizer_type == 'Adam':
        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
        
    # to prepare to train the model
    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
    
    # to add the initial value without training (for plotting from epoch 0)
    initial_loss_train, initial_accuracy_train = model.evaluate(train_ds, verbose=0)
    initial_loss_test, initial_accuracy_test = model.evaluate(test_ds, verbose=0)
    
    # to begin to train the model
    history = model.fit(train_ds, epochs=epoch, validation_data=valid_ds, verbose=2)  
    history.history['loss'].insert(0, initial_loss_train) # list
    history.history['accuracy'].insert(0, initial_accuracy_train)
    history.history['val_loss'].insert(0, initial_loss_test)
    history.history['val_accuracy'].insert(0, initial_accuracy_test)
    
    # model.save('my_model.keras')
    
    return model, history, test_ds, test_images_original


"""
Plotting the learning curve
"""    


def plot_learning_curves(history, epoch):
    """
    plotting the learning curve
    """

    
    print("Begin plotting the learning curve...") 
    plt.figure(figsize=(12, 5))

    epochs_range = range(epoch + 1)
    
    # Loss
    plt.figure(figsize=(6, 4))
    plt.plot(epochs_range, history.history['loss'], label='Training Loss', color='b')
    plt.plot(epochs_range, history.history['val_loss'], label='Validation Loss', linestyle='--', color='r')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss')
    plt.legend(loc='upper right')  
    plt.savefig('training_validation_loss.jpg')
    plt.show()  

    # Accuracy
    plt.figure(figsize=(6, 4))
    plt.plot(epochs_range, history.history['accuracy'], label='Training Accuracy', color='b')
    plt.plot(epochs_range, history.history['val_accuracy'], label='Validation Accuracy', linestyle='--', color='r')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title('Training and Validation Accuracy')
    plt.legend(loc='lower right')
    plt.savefig('training_validation_accuracy.jpg')
    plt.show()    
    print("Ending plotting the learning curve...") 


"""
Plotting confusion matrix
"""

def plot_confusion_matrix(model, test_ds, class_names):
    """
    plot_confusion_matrix
    """
   
    y_pred = []
    y_true = []
    for images, labels in test_ds:
        predictions = model.predict(images)
        y_pred.extend(tf.argmax(predictions, axis=1).numpy())
        y_true.extend(tf.argmax(labels, axis=1).numpy())
    
    # calculate the confusion matrix
    cm = tf.math.confusion_matrix(y_true, y_pred).numpy()
    print("Confusion Matrix Values:\n", cm)
    
    # heatmap for confusion matrix
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')
    plt.show()


"""
Saliency Map by DRISE
"""

def select_classified_img(model, class_names, test_ds, test_images_original, classname_1, classname_2, N):
    """
    To select specific images to generate saliency map
    e.g.
    classname_1 = CAT
    classname_2 = DOG
    meaning cat incorrectly classified to dog.
    """
    
    label_index_1 = class_names.index(classname_1)
    label_index_2 = class_names.index(classname_2)

    selected_indices = []
    selected_images = []
    selected_labels = []
    target_images = []
    entropys = []

    
    for i, (image, label) in enumerate(test_ds.unbatch()):
        prediction = model.predict(tf.expand_dims(image, 0))
        predicted_class = np.argmax(prediction, axis=1)[0]
        true_class = np.argmax(label.numpy(), axis=0)
        
        if true_class == label_index_1 and predicted_class == label_index_2:
            selected_indices.append(i)
            selected_images.append(image.numpy())
            selected_labels.append(label.numpy())
            target_images.append(test_images_original[i])  
            p_positive = prediction[prediction > 0]
            entropy = -np.sum(p_positive * np.log2(p_positive))  # avoid log(0)
            entropys.append(entropy)
            
            if len(selected_indices) >= N:
                break  

    if len(selected_indices) < N:
        print(f"Only find{len(selected_indices)} images that fulfilled the requirement，less than {N}。")
    
    return selected_indices, selected_images, selected_labels, target_images, entropys


"""
DRISE ALGORITHM
"""

def binary_mask(p1):
    """
    DRISE 1: Generating 5000 binary masks
    """
    p0 = 1 - p1
    masks = np.random.choice([0, 1], size=(5000, 16, 16), p=[p0, p1])
    
    # upsamling
    upsampled_masks = np.array([zoom(mask, zoom=(17/8, 17/8), order=0) for mask in masks])
    
    # cropping
    bin_masks = []
    for mask in upsampled_masks:
        start_x = random.randint(0, 2)
        start_y = random.randint(0, 2)
        end_x = start_x + 32
        end_y = start_y + 32
        bin_masks.append(mask[start_x:end_x, start_y:end_y])
    final_masks = np.array(bin_masks)
    
    assert final_masks.shape == (5000, 32, 32), "The final masks have incorrect shape."
    print('final_masks.shape is', final_masks.shape)
    
    return final_masks

def masked_img_generator(final_masks, selected_image):
    """
    DRISE 1: Masking a specific image
    """
    expanded_masks = np.expand_dims(final_masks, axis=-1)
    repeated_masks = np.repeat(expanded_masks, 3, axis=3)
    
    masked_images = selected_image * repeated_masks
    
    for masked_image in masked_images:
        assert masked_image.shape == (32, 32, 3), "The masked image has incorrect shape."
    
    return masked_images


def detection_proposal_generator(model, masked_images, batch_size=100):
    """
    DRISE 2: Generating proposals

    """    
    
    num_images = len(masked_images)
    proposals = np.zeros((num_images, 10))
    
    # here batch size is not batch size in resnet
    # batch size means how many proposals are generated at a time
    # if we have 50000 masked images, then batch size = 100, so 50 rounds is needed to generate proposals
    # it is just to speed up the run time
    
    for start_idx in range(0, num_images, batch_size):
        end_idx = min(start_idx + batch_size, num_images)
        batch_images = masked_images[start_idx:end_idx]        
        batch_predictions = model.predict(batch_images)        
        proposals[start_idx:end_idx] = batch_predictions
        
    assert proposals.shape == (num_images, 10), "The proposals have incorrect shape."
    print('proposals.shape is', proposals.shape)
    
    return proposals
    
        
def similarity_calculation(proposals, selected_label):
    """
    DRISE 3: generating the similarity score according to Petsuik
    """
    
    assert proposals.shape == (5000, 10), "The proposals have incorrect shape."
    print('proposals.shape is', proposals.shape)
    assert selected_label.shape == (10,), "The selected label has incorrect shape."
    print('selected_label.shape is', selected_label.shape)
    
   
    proposals_norm = np.linalg.norm(proposals, axis=1)
    
    selected_label_norm = np.linalg.norm(selected_label)
    
    dot_product = np.dot(proposals, selected_label)
    
    cosine_similarity = dot_product / (proposals_norm * selected_label_norm)
    
    assert cosine_similarity.shape[0] == 5000, "The similarity array has incorrect length."
    print('len(similarity_arr) is', cosine_similarity.shape[0])
    
    return cosine_similarity.tolist()


def weighted_sum(similarity_arr, binary_masks):
    """
    DRISE 4: generating the D-RISE matrix
    """
    
    assert binary_masks.shape == (5000, 32, 32), "The binary masks have incorrect shape."
    print('binary_masks.shape is', binary_masks.shape)
    
    similarity_arr_col = np.array(similarity_arr)[:, np.newaxis, np.newaxis]

    w_sum = np.sum(similarity_arr_col * binary_masks, axis=0)

    assert w_sum.shape == (32, 32), "The weighted sum has incorrect shape."
    print('w_sum.shape is', w_sum.shape)
    
    return w_sum




def plot_3d_matrix(w_norm, p1):
    """
    To show the scale problem
    """
    fig = plt.figure()
    ax = fig.add_subplot(111, projection='3d')
    x, y = np.meshgrid(np.arange(w_norm.shape[0]), np.arange(w_norm.shape[1]))
    surf = ax.plot_surface(x, y, w_norm, cmap='viridis', edgecolor='none')

    z_high = 1 * 5000 * p1  # upper bound
    z_low = 0.1 * 5000 * p1   # lower bound

    ax.plot_surface(x, y, np.full_like(w_norm, z_low), alpha=0.2, color='blue')
    ax.plot_surface(x, y, np.full_like(w_norm, z_high), alpha=0.2, color='red')
    ax.set_xlabel('X Index')
    ax.set_ylabel('Y Index')
    ax.set_zlabel('Value')
    ax.set_title('3D Surface Visualization of w_norm Matrix')
    fig.colorbar(surf, shrink=0.5, aspect=5)
    plt.show()


def heat_map(w_sum, target_image):
    """
    plot the saliency map
    """
    plt.figure(figsize=(8, 4))
    plt.subplot(1, 2, 1)
    plt.imshow(target_image, interpolation='nearest')
    plt.title('Original Image')
    plt.subplot(1, 2, 2)
    plt.imshow(target_image, interpolation='nearest')
    img = plt.imshow(w_sum, cmap='jet', alpha=0.5) 
    plt.title('Saliency Map')
    plt.colorbar(img, orientation='vertical')
    plt.show()


def saliency_map_for_classied_images(model, class_names, test_ds, test_images_original, classname_1, class_name_2, num_of_images, probability_masking):
    """
    To run from DRISE 1 TO 4 for specific image
    classname_1 is the true category
    classname_2 is the predicted category
    """
    selected_indices, selected_images, selected_labels, target_images, entropys_catcat = select_classified_img(model, class_names, test_ds, test_images_original, classname_1, class_name_2, num_of_images)
    for i in range(num_of_images):
        masked_images = masked_img_generator(binary_masks, selected_images[i]) 
        proposals = detection_proposal_generator(model, masked_images)
        similarity_arr = similarity_calculation(proposals,selected_labels[i])
        w_sum = weighted_sum(similarity_arr, binary_masks)
        plot_3d_matrix(w_sum, probability_masking) # p(1)
        heat_map(w_sum, target_images[i])



if __name__ == "__main__":
    
    """ DATA PREPARATION"""
    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
    
    #setup for data augmentation
    padding = 4
    image_size = 32 
    target_size = image_size + padding*2
    
    """ MODEL TRAINING"""
    #setup for model training
    epoch = 100
    batch_size = 128
    learning_rate = 0.1
    optimizer_type = 'SGD'
           
    # model training
    model, history, test_ds, test_images_original = main(batch_size, learning_rate, optimizer_type, epoch = epoch)  # 接收模型、训练历史和测试数据集
    
    # evaluate test dataset
    test_loss, test_accuracy = model.evaluate(test_ds, verbose=2)
    print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")
    
    # generate learning curve
    plot_learning_curves(history, epoch)
    
    # generate the confusion matrix
    plot_confusion_matrix(model, test_ds, class_names)

        
    """saliency map"""
    binary_masks = binary_mask(0.5) # M_i, i = 1,2,...,5000
    # cat classified as cat
    saliency_map_for_classied_images(model, class_names, test_ds, test_images_original, 'cat', 'cat', 5, 0.5)
    # cat classified as dog
    saliency_map_for_classied_images(model, class_names, test_ds, test_images_original, 'cat', 'dog', 5, 0.5)
    # you can plot saliency map as you want
  
    
    

